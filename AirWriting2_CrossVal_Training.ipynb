{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AirWriting-StepsToCrossValidation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbgu0x5R82nm",
        "colab_type": "text"
      },
      "source": [
        "## Codigo que permite conectar Colab con Google Drive\n",
        "Este codigo fué utilizado para aprobechar los recursos entregados por Google para asi poder realizar los entrenamientos, ya que no fué posible realizarlos en los computadores que se tenian disponibles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuqaLgVwbGtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "787fc582-5846-4a42-f19d-53d513235dbe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MpqrK9n7b8I",
        "colab_type": "text"
      },
      "source": [
        "# Cross Validation con Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e0DAs93s_47",
        "colab_type": "text"
      },
      "source": [
        "### Redimensionar imagenes a 64x64\n",
        "En este codigo se recorren las carpetas hasta llegar a los frames que se le reduce la dimension que tenia a 64x64 pixel, esto debido a que al usar la dimension 128x128 y pasar las imagenes vectorizadas a variable provocaba que el disco duro colapsara por un prolongado tiempo evitando que se pueda llevar a cabo este paso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDT6s9muub_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "cont = 0\n",
        "width = 64\n",
        "height = 64\n",
        "dim = (width, height)\n",
        "\n",
        "for FoldNumber in range(5):\n",
        "    \n",
        "    for NumberFolder in range(11):\n",
        "        \n",
        "        #print(NumberFolder)\n",
        "        \n",
        "        for NumberSample in range(64): # revisa sample por sample\n",
        "            \n",
        "            ListSample = os.listdir(\"Folders/Fold%d/%d/\" % ((FoldNumber+1),NumberFolder))\n",
        "            ListFrame = os.listdir(\"Folders/Fold%d/%d/%s/\" % ((FoldNumber+1),NumberFolder,ListSample[NumberSample]))\n",
        "            for NumberFrame in range(20):\n",
        "                buffer = (\"Folders/Fold%d/%d/%s/%s\" % ((FoldNumber+1),NumberFolder,ListSample[NumberSample],ListFrame[NumberFrame]))\n",
        "                buffer2 = (\"FoldersRedim/Fold%d/%d/%s/\" % ((FoldNumber+1),NumberFolder,ListSample[NumberSample]))\n",
        "                buffer3 = (\"FoldersRedim/Fold%d/%d/%s/%s\" % ((FoldNumber+1),NumberFolder,ListSample[NumberSample],ListFrame[NumberFrame]))\n",
        "                \n",
        "                img = cv2.imread(buffer, cv2.IMREAD_UNCHANGED)\n",
        "                \n",
        "\n",
        "                # resize image\n",
        "                resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "                cont = cont + 1 \n",
        "                \n",
        "                # Crea los directorios (Carpetas)\n",
        "                if os.path.isdir(buffer2):\n",
        "                    cv2.imsswrite(buffer3, resized)\n",
        "                else:\n",
        "                    os.makedirs(buffer2)\n",
        "                    cv2.imwrite(buffer3, resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRyzdzb6VhbD",
        "colab_type": "text"
      },
      "source": [
        "### Reduccion de muestras a la mitad\n",
        "Debido a la necesidad de bajar la cantidad de proceso realizado por el disco duro se vio la necesidad de disminir los datos a procesar, para esto se usa el codigo siguiente que de manera random mueve muestras de una carpeta a otra nueva para reducirlas a la mitad (en equilibrio, como todo debe ser -Thanos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErqNaqzaH5QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "import random\n",
        "# Se crea el la carpeta ThanosFolders si no está\n",
        "try:\n",
        "    os.stat(\"ThanosFolders\")  # Revisa si está el directorio\n",
        "except:\n",
        "    os.mkdir(\"ThanosFolders\") # Si no está lo crea \n",
        "# Se crean los 5 Fold\n",
        "for i in range(5):\n",
        "    try:\n",
        "        os.stat(\"ThanosFolders/Fold%d\" % (i+1))\n",
        "    except:\n",
        "        os.mkdir(\"ThanosFolders/Fold%d\" % (i+1))\n",
        "# Se crean carpetas fold/Numeros\n",
        "for j in range(5):\n",
        "    for i in range(11):\n",
        "        try:\n",
        "            os.stat(\"ThanosFolders/Fold%d/%d\" % ((j+1), i))\n",
        "        except:\n",
        "            os.mkdir(\"ThanosFolders/Fold%d/%d\" % ((j+1), i))\n",
        "\n",
        "\n",
        "ShortName = [\"BF\", \"GG\", \"JB\", \"JM\"]\n",
        "\n",
        "for FoldNumber in range(5):\n",
        "  for Number in range(11):\n",
        "    for ToMove in range(32):\n",
        "      FilesList = os.listdir(\"Folders/Fold%d/%d/\" % ((FoldNumber+1), Number))\n",
        "      \n",
        "      RandomFile = random.choice(FilesList)\n",
        "      \n",
        "      shutil.move(RandomFile, \n",
        "                  \"ThanosFolders/Fold%d/%d/\" % ((FoldNumber + 1), Number, File))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6hP6EuJqIJr",
        "colab_type": "text"
      },
      "source": [
        "### Pasar de 20 iamgenes .jpg a .csv \n",
        "\n",
        "Para generar los csv se juntaron las 20 imagenes de manera tridimencional, es decir, a cada imagen (64x64) se le agregó otra detras (64x64x2), luego se le agregó otra atras de las dos adjuntadas (quedando 64x64x3), hasta que se llegó a la dimension 64x64x20, todo esto usando la linea de codigo:\n",
        "* ImgStack = np.stack((img1, img2, img3, img4, img5, img6, img7, img8, img9, img10, img11, img12, img13, img14, img15, img16, img17, img18, img19, img20), axis = -1)\n",
        "\n",
        "Luego para almacenar las imagenes (Matrices) se guardaron diractamente a un csv dentro de una carpeta que los reunió todos juntos para luego poder ser consolidados en uno solo y asi poder tener la base de datos lista para pasarla a alguna variable como \"X\" e \"y\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBnzHXueqIJ8",
        "colab_type": "code",
        "colab": {},
        "outputId": "41a20abf-493e-4ae8-e8c1-4860ab231ef6"
      },
      "source": [
        "import cv2\n",
        "import numpy as np # Imagen a Matriz\n",
        "import os\n",
        "import pandas as pd # Matriz a .csv\n",
        "\n",
        "# Creacion de nuevo directorio que contendrá solo .csv\n",
        "try:\n",
        "    os.stat(\"SamplesCSV\")  # Revisa si está el directorio\n",
        "except:\n",
        "    os.mkdir(\"SamplesCSV\") # Si no está lo crea \n",
        "\n",
        "# Se crean los 5 Fold\n",
        "#for i in range(5):\n",
        "#    try:\n",
        "#        os.stat(\"FoldsCSV/Fold%d\" % (i+1))\n",
        "#    except:\n",
        "#        os.mkdir(\"FoldsCSV/Fold%d\" % (i+1))\n",
        "\n",
        "ShortName = [\"BF\", \"GG\", \"JB\", \"JM\"]\n",
        "\n",
        "for FoldNumber in range(5):\n",
        "    for Number in range(11):\n",
        "        NumberName = 0 # contador de samples revisados\n",
        "        for SampleNumber in range(320): # revisa sample por sample\n",
        "            \n",
        "            if SampleNumber == 80 or SampleNumber == 160 or SampleNumber == 240: # para recorrer ShortName[NumberName]\n",
        "                NumberName = NumberName + 1\n",
        "            if (os.path.isdir(\"Folders/Fold%d/%d/Sample-%s-%02d%03d\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1)))): # lo siguiente se realiza solo si el directorio se encuentra\n",
        "                FrameNumber = 1\n",
        "                \n",
        "                # Se pasa de 20 Imagenes.jpg a 20 Matrices 2D\n",
        "                for Frames in range(1, 21): # recorre los 20 frames partiendo con Frames=1\n",
        "                    \n",
        "                    while not (os.path.isfile(\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber))):\n",
        "                        FrameNumber += 1 # si no existe la imagen Frame# se busca Frame(#+1) \n",
        "                    \n",
        "                    if Frames == 1:\n",
        "                        img1 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 2:\n",
        "                        img2 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 3:\n",
        "                        img3 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 4:\n",
        "                        img4 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 5:\n",
        "                        img5 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 6:\n",
        "                        img6 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 7:\n",
        "                        img7 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 8:\n",
        "                        img8 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 9:\n",
        "                        img9 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 10:\n",
        "                        img10 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 11:\n",
        "                        img11 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 12:\n",
        "                        img12 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 13:\n",
        "                        img13 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 14:\n",
        "                        img14 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 15:\n",
        "                        img15 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 16:\n",
        "                        img16 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 17:\n",
        "                        img17 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 18:\n",
        "                        img18 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 19:\n",
        "                        img19 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "                    elif Frames == 20:\n",
        "                        img20 = cv2.imread((\"Folders/Fold%d/%d/Sample-%s-%02d%03d/Frame%d.jpg\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1), FrameNumber)), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "                    FrameNumber += 1\n",
        "                        \n",
        "                # 20 Matriz 2D a una Matriz 3D\n",
        "                ImgStack = np.stack((img1, img2, img3, img4, img5, img6, img7, img8, img9, img10, img11, img12, img13, img14, img15, img16, img17, img18, img19, img20), axis = -1)\n",
        "                \n",
        "                # Se guarda la Matriz 3D como .csv\n",
        "                ImgStack.tofile(\"SamplesCSV/Sample-%s-%02d%03d.csv\" % (ShortName[NumberName], Number, (SampleNumber+1)), sep=',', format='%d')\n",
        "\n",
        "print(ImgStack.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 128, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt-uvZ_AqILa",
        "colab_type": "text"
      },
      "source": [
        "### Revisa si hay carpetas samples con menos de 20 imagenes\n",
        "Si las hay, imprime las encontradas. Esto se utilizó para revisar algunos salmples que quedaron defectuosos en los pasos iniciales (Cortar videos largos a videos de 2 segundos, o generacion de frames a partir de los videos cortos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RS05snWqILf",
        "colab_type": "code",
        "colab": {},
        "outputId": "7b1275bb-7c37-4b31-9cf3-ec286889cafb"
      },
      "source": [
        "ShortName = [\"BF\", \"GG\", \"JB\", \"JM\"]\n",
        "\n",
        "for FoldNumber in range(5):\n",
        "    for Number in range(11):\n",
        "        NumberName = 0 # contador de samples revisados\n",
        "        for SampleNumber in range(320): # revisa sample por sample\n",
        "            \n",
        "            if SampleNumber == 80 or SampleNumber == 160 or SampleNumber == 240: # para recorrer ShortName[NumberName]\n",
        "                NumberName = NumberName + 1\n",
        "            if (os.path.isdir(\"Folders/Fold%d/%d/Sample-%s-%02d%03d\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1)))): # lo siguiente se realiza solo si el directorio se encuentra\n",
        "                FrameNumber = 1\n",
        "                    \n",
        "                FilesList = os.listdir(\"Folders/Fold%d/%d/Sample-%s-%02d%03d\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1)))\n",
        "                FilesCount = len(FilesList) # cantidad de archivos en carpeta samples\n",
        "                if FilesCount < 20:\n",
        "                    print(\"Folders/Fold%d/%d/Sample-%s-%02d%03d\" % ((FoldNumber+1), Number, ShortName[NumberName], Number, (SampleNumber+1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folders/Fold4/3/Sample-BF-03056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpoDwx5QqIMc",
        "colab_type": "text"
      },
      "source": [
        "### Consolidación de archivos .csv\n",
        "Para consolidar los archivos .csv se recurrió a la consola de comandos (cmd) usando el siguiente comando en el directorio donde se encontraban todos los csv juntos:\n",
        "\n",
        "**copy *.csv X.csv**\n",
        "\n",
        "Lo que hace es copiar todos los archivos con la extencion .csv y los pega (consolidando) en el archivo X.csv creado por el mismo comando"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljI3tsHaqIMh",
        "colab_type": "text"
      },
      "source": [
        "### Creación de y.csv\n",
        "La creación de y.csv al ser mas simple se hizo a mano con Excel siguiendo el orden de todos los Samples-XX-00000.csv, dejando una sola columna con los numeros correspondientes (0 repetido 80 veces hacia abajo, 1 repetido 80 veces hacia abajo, ..., 10 repetido 80 veces hacia abajo. Todo esto repetido 4 veces (80 * 11 * 4 = 3520 Samples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9Qq5VVzqIMx",
        "colab_type": "text"
      },
      "source": [
        "### Pasar de X.csv a variable\n",
        "Para intentar tener la variable \"X\" conteniendo todas la imagenes y asi dividirlas con la funcion de sklearn:\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "se usó el siguiente código, que resultó ser demasiado proceso para un disco duro convencional HDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkydLgPvqINB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### TESTEO  1 ######\n",
        "# NO EJECUTAR!!!!\n",
        "import csv\n",
        "\n",
        "results = []\n",
        "with open(\"C:/Users/Joselmq/Documents/Sistemas Inteligentes/Imagenes/y.csv\") as csvfile:\n",
        "    reader = csv.reader(csvfile, quoting=csv.QUOTE_NONNUMERIC)\n",
        "#    for row in reader: # each row is a list\n",
        "#        results.append(row)\n",
        "\n",
        "\n",
        "###### TESTEO 2 ######\n",
        "#NO EJECUTAR!!!!\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "#X = pd.read_csv(\"https://drive.google.com/file/d/1TBSXTgqIh8ZdLnAlnKZ78llabH0TpnAp/view?usp=sharing\")\n",
        "#y = pd.read_csv(\"https://drive.google.com/file/d/1XobxzrM6qzwpRevxvnmFhpd_yg4fQshj/view?usp=sharing\")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i94PDhuHRdku",
        "colab_type": "text"
      },
      "source": [
        "## Regresión Logística\n",
        "Primero, para este código, por cosas de la libreria, se requería de que la base de datos estuviera en una sola carpeta (en este caso ubica en el drive), que los archivos estuvieran en formato imagen y en escala de grises, lo cual eran fundamentales para el entrenamiento, pero por problemas de tamaño del arreglo no pudo llevarse a cabo un entrenamiento exitoso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0dsIfZq3_JD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d2629b7b-f555-456f-df2b-f7ecd9ff80be"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import tensorflow as tf\n",
        "\n",
        "XY_dategen = ImageDataGenerator()\n",
        "XY_generator = XY_dategen.flow_from_directory(\n",
        "    #dependera de quien vea la direcion\n",
        "    #jose\n",
        "    #directory=r\"/content/gdrive/My Drive/2019/Sistemas Inteligentes/Proyecto Air Writing Grupo 4/Entrega 2/DataSet/1Fold\",\n",
        "    #gabriel\n",
        "    directory=r\"/content/gdrive/My Drive/Proyecto Air Writing Grupo 4/Entrega 2/DataSet/1Fold\",\n",
        "    target_size=(1280, 64), color_mode=\"grayscale\", batch_size=32, class_mode=\"categorical\", shuffle=True, seed=42)\n",
        "X, Y = XY_generator.next()  #or next(train_generator)\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2 ) # training to testing ratio is 0.8:0.2\n",
        "# split the data with 50% in each set\n",
        "#X1, X2, y1, y2\n",
        "\n",
        "# fit the model on one set of data\n",
        "model = LogisticRegression(C = 10**3, solver='newton-cg', multi_class='multinomial')\n",
        "#model.add(Flatten())\n",
        "\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# evaluate the model on the second set of data\n",
        "Y_test_model = model.predict(X_test)\n",
        "accuracy_score(Y_test, Y_test_model)\n",
        "\n",
        "print (X_train.shape, Y_train.shape)\n",
        "print (X_test.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3520 images belonging to 11 classes.\n",
            "(25, 1280, 64, 1) (25, 11)\n",
            "(7, 1280, 64, 1) (7, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTvCTOFHHqGo",
        "colab_type": "text"
      },
      "source": [
        "### <<<<<<<<<<<<<<<< Hasta acá se llegó con Sklearn >>>>>>>>>>>>>>>>\n",
        "    (debido a errodes de falta de memoria al cargar datos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tF3bdjECyx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y2_model = model.fit(X1, y1).predict(X2)\n",
        "y1_model = model.fit(X2, y2).predict(X1)\n",
        "accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk8ckEfQDOTS",
        "colab_type": "text"
      },
      "source": [
        "### Realización de la validación cruzada\n",
        "En esta parte se generan 5 particiones del dataset y se hace el entrenamiento 5 veces, cada vez usando un batch distinto para el validate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDacGw32Cy_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cross_validation import cross_val_score\n",
        "cross_val_score(model, X, y, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUVMu12IF4lu",
        "colab_type": "text"
      },
      "source": [
        "### Metodos para mejorar el entrenamiento\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3M6A7NlCzGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def PolynomialRegression(degree=2, **kwargs):\n",
        "    return make_pipeline(PolynomialFeatures(degree),\n",
        "                         LinearRegression(**kwargs))\n",
        "  \n",
        "import numpy as np\n",
        "\n",
        "def make_data(N, err=1.0, rseed=1):\n",
        "    # randomly sample the data\n",
        "    rng = np.random.RandomState(rseed)\n",
        "    X = rng.rand(N, 1) ** 2\n",
        "    y = 10 - 1. / (X.ravel() + 0.1)\n",
        "    if err > 0:\n",
        "        y += err * rng.randn(N)\n",
        "    return X, y\n",
        "\n",
        "X, y = make_data(40)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn; seaborn.set()  # plot formatting\n",
        "\n",
        "X_test = np.linspace(-0.1, 1.1, 500)[:, None]\n",
        "\n",
        "plt.scatter(X.ravel(), y, color='black')\n",
        "axis = plt.axis()\n",
        "for degree in [1, 3, 5]:\n",
        "    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)\n",
        "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
        "plt.xlim(-0.1, 1.0)\n",
        "plt.ylim(-2, 12)\n",
        "plt.legend(loc='best');\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "\n",
        "from sklearn.learning_curve import validation_curve\n",
        "degree = np.arange(0, 21)\n",
        "train_score, val_score = validation_curve(PolynomialRegression(), X, y,\n",
        "                                          'polynomialfeatures__degree', degree, cv=7)\n",
        "\n",
        "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel('degree')\n",
        "plt.ylabel('score');\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "\n",
        "plt.scatter(X.ravel(), y)\n",
        "lim = plt.axis()\n",
        "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n",
        "plt.plot(X_test.ravel(), y_test);\n",
        "plt.axis(lim);\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "\n",
        "degree = np.arange(21)\n",
        "train_score2, val_score2 = validation_curve(PolynomialRegression(), X2, y2,\n",
        "                                            'polynomialfeatures__degree', degree, cv=7)\n",
        "\n",
        "plt.plot(degree, np.median(train_score2, 1), color='blue', label='training score')\n",
        "plt.plot(degree, np.median(val_score2, 1), color='red', label='validation score')\n",
        "plt.plot(degree, np.median(train_score, 1), color='blue', alpha=0.3, linestyle='dashed')\n",
        "plt.plot(degree, np.median(val_score, 1), color='red', alpha=0.3, linestyle='dashed')\n",
        "plt.legend(loc='lower center')\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel('degree')\n",
        "plt.ylabel('score');\n",
        "\n",
        "\n",
        "############################################\n",
        "\n",
        "\n",
        "from sklearn.learning_curve import learning_curve\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "\n",
        "for i, degree in enumerate([2, 9]):\n",
        "    N, train_lc, val_lc = learning_curve(PolynomialRegression(degree),\n",
        "                                         X, y, cv=7,\n",
        "                                         train_sizes=np.linspace(0.3, 1, 25))\n",
        "\n",
        "    ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='training score')\n",
        "    ax[i].plot(N, np.mean(val_lc, 1), color='red', label='validation score')\n",
        "    ax[i].hlines(np.mean([train_lc[-1], val_lc[-1]]), N[0], N[-1],\n",
        "                 color='gray', linestyle='dashed')\n",
        "\n",
        "    ax[i].set_ylim(0, 1)\n",
        "    ax[i].set_xlim(N[0], N[-1])\n",
        "    ax[i].set_xlabel('training size')\n",
        "    ax[i].set_ylabel('score')\n",
        "    ax[i].set_title('degree = {0}'.format(degree), size=14)\n",
        "    ax[i].legend(loc='best')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQVmkxmTqIN1",
        "colab_type": "text"
      },
      "source": [
        "# Método Keras (Test, Train, Valid)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7vyyfz87B_-",
        "colab_type": "text"
      },
      "source": [
        "### Crear carpeta CVFolders\n",
        "\n",
        "Manualmete se creó la carpeta CVFolders y dentro de ella se crearon las carpetas Test, Train y Valid. Se pegó el contenido de los  3 primeros Folds para Train (60%), el Fold4 para Valid (20%) y el ultimo Fold5 para Test (20%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa7zJnmt7CkO",
        "colab_type": "text"
      },
      "source": [
        "### Juntar las 20 imágenes en una de manera horizontal\n",
        "En la carpeta \"CrossValidationFolder\" se crean tres subcarpetas (Train, Test y Valid) en las que se crean las uniones de las secuencias de imagenes de cada sample ubicado en CVFolders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqxEmWzWqIOF",
        "colab_type": "code",
        "colab": {},
        "outputId": "77c48572-57ee-48d1-b83e-70cd349ccb32"
      },
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import os\n",
        "import re #Split\n",
        "\n",
        "\n",
        "# para ordenar correctamente la lista de imagenes en el directorio\n",
        "def sorted_aphanumeric(data): \n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(data, key=alphanum_key)\n",
        "\n",
        "\n",
        "# Arrays para recorrer directorios\n",
        "TestTrainValid = [\"Test\", \"Train\", \"Valid\"]\n",
        "ShortName = [\"BF\", \"GG\", \"JB\", \"JM\"]\n",
        "\n",
        "\n",
        "# Se crea el la carpeta CrossValidationFolder si no está\n",
        "try: \n",
        "    os.stat(\"CrossValidationFolder\")\n",
        "except:\n",
        "    os.mkdir(\"CrossValidationFolder\")\n",
        "# Se crean las carpetas \"Test\", \"Train\" y \"Valid\"\n",
        "for i in range(3): \n",
        "    try:\n",
        "        os.stat(\"CrossValidationFolder/%s\" % TestTrainValid[i])\n",
        "    except:\n",
        "        os.mkdir(\"CrossValidationFolder/%s\" % TestTrainValid[i])\n",
        "# Se crean carpetas Numeros\n",
        "for j in range(3):\n",
        "    for i in range(11):\n",
        "        if j == 0:\n",
        "            try:\n",
        "                os.stat(\"CrossValidationFolder/%s/Test_folder\" % TestTrainValid[j])\n",
        "            except:\n",
        "                os.mkdir(\"CrossValidationFolder/%s/Test_folder\" % TestTrainValid[j])\n",
        "        else:\n",
        "            try:\n",
        "                os.stat(\"CrossValidationFolder/%s/Class_%d\" % (TestTrainValid[j], i))\n",
        "            except: \n",
        "                os.mkdir(\"CrossValidationFolder/%s/Class_%d\" % (TestTrainValid[j], i))\n",
        "\n",
        "\n",
        "for Folds in range(len(TestTrainValid)):\n",
        "    for Number in range(11):\n",
        "        NumberName = 0\n",
        "        for SampleNumber in range(320):\n",
        "            if SampleNumber == 80 or SampleNumber == 160 or SampleNumber == 240: # para recorrer ShortName[NumberName]\n",
        "                NumberName = NumberName + 1\n",
        "            if (os.path.isdir(\"CVFolders/%s/%d/Sample-%s-%02d%03d\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1)))):\n",
        "                \n",
        "                FilesList = sorted_aphanumeric(os.listdir(\"CVFolders/%s/%d/Sample-%s-%02d%03d\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1)))) # Ordena archivos en directorio\n",
        "                list_im = [\"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[0]),\n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[1]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[2]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[3]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[4]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[5]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[6]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[7]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[8]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[9]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[10]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[11]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[12]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[13]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[14]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[15]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[16]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[17]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[18]), \n",
        "                           \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[19]),]\n",
        "                \n",
        "                imgs = [ PIL.Image.open(i) for i in list_im ]\n",
        "                # pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
        "                min_shape = sorted([(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
        "                imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
        "\n",
        "                # save that beautiful picture\n",
        "                imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
        "                if Folds == 0:\n",
        "                    imgs_comb.save(\"CrossValidationFolder/%s/Test_folder/Sample-%s-%02d%03d.jpg\" % (TestTrainValid[Folds], ShortName[NumberName], Number, (SampleNumber+1)))   \n",
        "                else:\n",
        "                    imgs_comb.save(\"CrossValidationFolder/%s/Class_%d/Sample-%s-%02d%03d.jpg\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1)))   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__WQzK4wyAVq",
        "colab_type": "text"
      },
      "source": [
        "### Juntar las 20 imágenes en una de manera horizontal (Con reducción de muestras)\n",
        "Debido a la falta de memoria y de los computadores de la plataforma Colab () se redujeron la cantidad de muestras para así poder ejecutar las muestras a las variables correspondientes a train, test y valid.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Error mostrado por Colab\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Te estás quedando sin espacio en la memoria\n",
        "Tu entorno de ejecución se está quedando sin espacio en la memoria. Si se sigue empleando, es posible que se produzca un error por falta de memoria y que se pierda el estado en memoria de todas las sesiones. ¿Quieres finalizar algunas sesiones para liberar memoria (dichas sesiones perderán su estado)? Actualmente se están utilizando 10.79 GB de 12.72 GB.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "la reduccion de muestras se hizo de manera equitativa, lo que significa, que la cantidad de muestras finales es la misma por cada integrante y número, conservando tambien la proporcion de los distintos tamaños de muestras entre Train y las otras dos carpetas, usando (numero * i) para realizar el ajuste (i es 3 para Train y 1 en caso contrario). \n",
        "\n",
        "\n",
        "Primero se probó el número 20 para multiplicar \"i\" (20 muestras por cada personas y en cada numero), lo que no mantuvo la proporcionalidad requerida debido a que las muestras fueron repartidas aleatoriamente entre los 5 folds en pasos anteriores, por lo que en algunos numero no se llegaba a las 20 muestras por personas.\n",
        "\n",
        "\n",
        "Luego se probó con el numero 10 y se procedió con los pasos posteriores, pero al pasar los datos a los Xtrain y Xtest el programa mostró falta de memoria. Despues se cambió el 10 por el 5 y el 5 por el 2 resultando en el mismo problema de no poder cargar los datos.\n",
        "\n",
        "\n",
        "---\n",
        " if ((NumberName == 0 and CountToReduceSamples < (2 * i)) or (NumberName == 1 and CountToReduceSamples < (4 * i)) or (NumberName == 2 and CountToReduceSamples < (6 * i)) or (NumberName == 3 and CountToReduceSamples < (8 * i))):\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suOy_w3Px9Po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import os\n",
        "import re #Split\n",
        "import cv2\n",
        "\n",
        "\n",
        "# para ordenar correctamente la lista de imagenes en el directorio\n",
        "def sorted_aphanumeric(data): \n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
        "    return sorted(data, key=alphanum_key)\n",
        "\n",
        "\n",
        "# Arrays para recorrer directorios\n",
        "TestTrainValid = [\"Test\", \"Train\", \"Valid\"]\n",
        "ShortName = [\"BF\", \"GG\", \"JB\", \"JM\"]\n",
        "\n",
        "\n",
        "# Se crea el la carpeta CrossValidationFolder si no está\n",
        "try: \n",
        "    os.stat(\"CrossValidationFolderSmallRedim\")\n",
        "except:\n",
        "    os.mkdir(\"CrossValidationFolderSmallRedim\")\n",
        "# Se crean las carpetas \"Test\", \"Train\" y \"Valid\"\n",
        "for i in range(3): \n",
        "    try:\n",
        "        os.stat(\"CrossValidationFolderSmallRedim/%s\" % TestTrainValid[i])\n",
        "    except:\n",
        "        os.mkdir(\"CrossValidationFolderSmallRedim/%s\" % TestTrainValid[i])\n",
        "# Se crean carpetas Numeros\n",
        "for j in range(3):\n",
        "    for i in range(11):\n",
        "        if j == 0:\n",
        "            try:\n",
        "                os.stat(\"CrossValidationFolderSmallRedim/%s/Test_folder\" % TestTrainValid[j])\n",
        "            except:\n",
        "                os.mkdir(\"CrossValidationFolderSmallRedim/%s/Test_folder\" % TestTrainValid[j])\n",
        "        else:\n",
        "            try:\n",
        "                os.stat(\"CrossValidationFolderSmallRedim/%s/%d\" % (TestTrainValid[j], i))\n",
        "            except: \n",
        "                os.mkdir(\"CrossValidationFolderSmallRedim/%s/%d\" % (TestTrainValid[j], i))\n",
        "\n",
        "                \n",
        "\n",
        "for Folds in range(len(TestTrainValid)):\n",
        "    if Folds == 1: # si fold = Train   (donde hay 3 folds) (por problemas de memoria)\n",
        "        i = 3 # multiplicador cantidad de muestras a pasar a CrossValidationFolderRedim\n",
        "    else:\n",
        "        i = 1\n",
        "    for Number in range(11):\n",
        "        NumberName = 0\n",
        "        CountToReduceSamples = 0\n",
        "        for SampleNumber in range(320):\n",
        "            if SampleNumber == 80 or SampleNumber == 160 or SampleNumber == 240: # para recorrer ShortName[NumberName]\n",
        "                NumberName = NumberName + 1\n",
        "            # Solo extrae 2 muestras de cada persona por cada \"CVFolders/(Train, Test o Valid)/(0 a 10)      (40 muestras \"0\": 8 muestras de Test, 8 de Train y 24 de Test)\n",
        "            if ((NumberName == 0 and CountToReduceSamples < (2 * i)) or (NumberName == 1 and CountToReduceSamples < (4 * i)) or (NumberName == 2 and CountToReduceSamples < (6 * i)) or (NumberName == 3 and CountToReduceSamples < (8 * i))):\n",
        "                if (os.path.isdir(\"CVFolders/%s/%d/Sample-%s-%02d%03d\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1)))):\n",
        "                    #print(\"CVFolders/%s/%d/Sample-%s-%02d%03d\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1)))\n",
        "                    FilesList = sorted_aphanumeric(os.listdir(\"CVFolders/%s/%d/Sample-%s-%02d%03d\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1)))) # Ordena archivos en directorio\n",
        "                    list_im = [\"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[0]),\n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[1]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[2]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[3]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[4]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[5]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[6]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[7]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[8]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[9]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[10]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[11]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[12]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[13]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[14]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[15]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[16]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[17]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[18]), \n",
        "                               \"CVFolders/%s/%d/Sample-%s-%02d%03d/%s\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1), FilesList[19]),]\n",
        "\n",
        "                    imgs = [ PIL.Image.open(i) for i in list_im ]\n",
        "                    # pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
        "                    min_shape = sorted([(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
        "                    imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
        "\n",
        "                    # save that beautiful picture\n",
        "                    imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
        "                    if Folds == 0:\n",
        "                        imgs_comb.save(\"CrossValidationFolderSmallRedim/%s/Test_folder/Sample-%s-%02d%03d.jpg\" % (TestTrainValid[Folds], ShortName[NumberName], Number, (SampleNumber+1)))   \n",
        "                    else:\n",
        "                        imgs_comb.save(\"CrossValidationFolderSmallRedim/%s/%d/Sample-%s-%02d%03d.jpg\" % (TestTrainValid[Folds], Number, ShortName[NumberName], Number, (SampleNumber+1)))\n",
        "                    CountToReduceSamples += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3h-K86pqIPK",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation con Keras\n",
        "\n",
        "Acá se buscan los parametros necesarios para hacer correr el entrenamiento.\n",
        "\n",
        "Pagina guía:\n",
        "\n",
        "https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
        "\n",
        "Paginas de ayuda:\n",
        "\n",
        "https://keras.io/layers/core/#flatten\n",
        "\n",
        "https://keras.io/getting-started/sequential-model-guide/\n",
        "\n",
        "https://keras.io/models/sequential/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8cXQ_GzdYSx",
        "colab_type": "text"
      },
      "source": [
        "### Generador de Train, Valid, Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVS7pcW5qIPP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "93c233e6-dfe5-4820-c1fd-7a9ec571a18b"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "valid_datagen = ImageDataGenerator()\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=r\"/content/gdrive/My Drive/2019/Sistemas Inteligentes/Proyecto Air Writing Grupo 4/Entrega 2/DataSet/CrossValidationFolderSmallRedim/Train/\",\n",
        "    target_size=(1280, 64),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "'''\n",
        "The directory must be set to the path where your ‘n’ classes of folders are present.\n",
        "The target_size is the size of your input images, every image will be resized to this size.\n",
        "color_mode: if the image is either black and white or grayscale set “grayscale” or if the image has three colour channels, set “rgb”.\n",
        "batch_size: No. of images to be yielded from the generator per batch.\n",
        "class_mode: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both input and the output would probably be the same image, for this case set to “input”.\n",
        "shuffle: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n",
        "seed: Random seed for applying random image augmentation and shuffling the order of the image.\n",
        "'''\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory=r\"/content/gdrive/My Drive/2019/Sistemas Inteligentes/Proyecto Air Writing Grupo 4/Entrega 2/DataSet/CrossValidationFolderSmallRedim/Valid/\",\n",
        "    target_size=(1280, 64),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "'''Same as train generator settings except for obvious changes like directory path.'''\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory=r\"/content/gdrive/My Drive/2019/Sistemas Inteligentes/Proyecto Air Writing Grupo 4/Entrega 2/DataSet/CrossValidationFolderSmallRedim/Test/\",\n",
        "    target_size=(1280, 64),\n",
        "    color_mode=\"grayscale\",\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "'''directory: path where there exists a folder, under which all the test images are present. For example, in this case, the images are found in /test/test_images/\n",
        "batch_size: Set this to some number that divides your total number of images in your test set exactly.\n",
        "Why this only for test_generator?\n",
        "Actually, you should set the “batch_size” in both train and valid generators to some number that divides your total number of images in your train set and valid respectively, but this doesn’t matter before because even if batch_size doesn’t match the number of samples in the train or valid sets and some images gets missed out every time we yield the images from generator, but it would be sampled the very next epoch you train.\n",
        "But for the test set, you should sample the images exactly once, no less or no more. If Confusing, just set it to 1(but maybe a little bit slower).\n",
        "class_mode: Set this to None, to return only the images.\n",
        "shuffle: Set this to False, because you need to yield the images in “order”, to predict the outputs and match them with their unique ids or filenames.'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 264 images belonging to 11 classes.\n",
            "Found 88 images belonging to 11 classes.\n",
            "Found 88 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'directory: path where there exists a folder, under which all the test images are present. For example, in this case, the images are found in /test/test_images/\\nbatch_size: Set this to some number that divides your total number of images in your test set exactly.\\nWhy this only for test_generator?\\nActually, you should set the “batch_size” in both train and valid generators to some number that divides your total number of images in your train set and valid respectively, but this doesn’t matter before because even if batch_size doesn’t match the number of samples in the train or valid sets and some images gets missed out every time we yield the images from generator, but it would be sampled the very next epoch you train.\\nBut for the test set, you should sample the images exactly once, no less or no more. If Confusing, just set it to 1(but maybe a little bit slower).\\nclass_mode: Set this to None, to return only the images.\\nshuffle: Set this to False, because you need to yield the images in “order”, to predict the outputs and match them with their unique ids or filenames.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEAuKrYhdilq",
        "colab_type": "text"
      },
      "source": [
        "### Prueba de distintos modelos de entrenamiento\n",
        "Se realizó una gran cantidad de pruebas modificando los distintos parametros, llegando a lo siguiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX47pB73qV6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "cd77aa9d-1f02-4e00-bfd6-09434f198764"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras import regularizers, optimizers\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "\n",
        "'''from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np'''\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#layer1\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(1280,64,1)))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Layer2\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "#layer Output\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(11, activation='softmax'))\n",
        "model.compile(optimizers.rmsprop(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"SGD\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adagrad\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adadelta\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "#model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adamax\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Nadam\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=20\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 5s 630ms/step - loss: 6.7403 - acc: 0.1131 - val_loss: 2.3984 - val_acc: 0.0714\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 2s 195ms/step - loss: 2.3973 - acc: 0.0977 - val_loss: 2.3953 - val_acc: 0.0893\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 2.4545 - acc: 0.1052 - val_loss: 2.3969 - val_acc: 0.1094\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 177ms/step - loss: 2.4892 - acc: 0.1092 - val_loss: 2.3961 - val_acc: 0.0893\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 1s 178ms/step - loss: 2.4078 - acc: 0.1210 - val_loss: 2.3880 - val_acc: 0.2143\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 2.3229 - acc: 0.2130 - val_loss: 2.2630 - val_acc: 0.3281\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 179ms/step - loss: 2.2336 - acc: 0.2170 - val_loss: 1.8807 - val_acc: 0.2857\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 2.1568 - acc: 0.2446 - val_loss: 1.7012 - val_acc: 0.4107\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 1.9119 - acc: 0.3488 - val_loss: 1.6458 - val_acc: 0.4531\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 1.5243 - acc: 0.5065 - val_loss: 1.2811 - val_acc: 0.6250\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 2s 196ms/step - loss: 1.3849 - acc: 0.5352 - val_loss: 1.1231 - val_acc: 0.6250\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 1.1628 - acc: 0.6196 - val_loss: 0.7942 - val_acc: 0.7656\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 1.2944 - acc: 0.5553 - val_loss: 0.7569 - val_acc: 0.7857\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 1.0079 - acc: 0.6620 - val_loss: 0.6398 - val_acc: 0.8036\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 0.6789 - acc: 0.7608 - val_loss: 0.4431 - val_acc: 0.8594\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 0.7469 - acc: 0.7421 - val_loss: 0.5085 - val_acc: 0.8750\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 0.6343 - acc: 0.7945 - val_loss: 0.8663 - val_acc: 0.7143\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 0.8229 - acc: 0.7619 - val_loss: 0.4540 - val_acc: 0.8438\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 0.4244 - acc: 0.8420 - val_loss: 0.4104 - val_acc: 0.9107\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.4455 - acc: 0.8477 - val_loss: 0.4520 - val_acc: 0.8929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1a8a953e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJydvU6D_yRx",
        "colab_type": "text"
      },
      "source": [
        "Después de lo anterior, de notó que en muchas epochs se llegaba a un resultado cercano a 1 pero no llegaba a la solución, por lo que se decidió disminuir el valor de learning rate (lr) un poco para que así recorra una menor distancia entre cada epoch y de esa manera no se pase demasiado del resultado deseado.\n",
        "\n",
        "* Disminucion de 0.001 a 0.0007"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ohfc4kW7Cv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "119a0b11-68ba-48bd-c346-68f8279944bf"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras import regularizers, optimizers\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "\n",
        "'''from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np'''\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#layer1\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(1280,64,1)))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Layer2\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "#layer Output\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(11, activation='softmax'))\n",
        "model.compile(optimizers.rmsprop(lr=0.0007, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"SGD\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adagrad\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adadelta\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adam\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adamax\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Nadam\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=20\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 5s 648ms/step - loss: 12.7035 - acc: 0.0830 - val_loss: 13.4848 - val_acc: 0.0357\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 2s 193ms/step - loss: 6.3582 - acc: 0.0977 - val_loss: 2.3930 - val_acc: 0.1786\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 2.4002 - acc: 0.0948 - val_loss: 2.3908 - val_acc: 0.1875\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 2.3776 - acc: 0.1394 - val_loss: 2.3771 - val_acc: 0.1607\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 2.3745 - acc: 0.1422 - val_loss: 2.3639 - val_acc: 0.1964\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 2.2774 - acc: 0.1670 - val_loss: 2.2872 - val_acc: 0.2031\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 2.2696 - acc: 0.1566 - val_loss: 1.9854 - val_acc: 0.3929\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 1.8947 - acc: 0.3721 - val_loss: 1.4795 - val_acc: 0.6250\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 1.7055 - acc: 0.3933 - val_loss: 1.4001 - val_acc: 0.5781\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 1s 180ms/step - loss: 1.4360 - acc: 0.4986 - val_loss: 0.9869 - val_acc: 0.7321\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 2s 199ms/step - loss: 1.2035 - acc: 0.6133 - val_loss: 0.7999 - val_acc: 0.8571\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 183ms/step - loss: 1.0821 - acc: 0.6498 - val_loss: 0.6234 - val_acc: 0.8750\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 0.8854 - acc: 0.6699 - val_loss: 0.7090 - val_acc: 0.8393\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 182ms/step - loss: 0.7408 - acc: 0.7421 - val_loss: 0.3501 - val_acc: 0.9107\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 0.6115 - acc: 0.7604 - val_loss: 0.3064 - val_acc: 0.9219\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 0.5657 - acc: 0.7974 - val_loss: 0.4304 - val_acc: 0.8929\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 0.3237 - acc: 0.8908 - val_loss: 0.3467 - val_acc: 0.8393\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 1s 186ms/step - loss: 0.4445 - acc: 0.8394 - val_loss: 0.4607 - val_acc: 0.8750\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 1s 184ms/step - loss: 0.5352 - acc: 0.8197 - val_loss: 0.6692 - val_acc: 0.8750\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 2s 202ms/step - loss: 0.3231 - acc: 0.8984 - val_loss: 0.1584 - val_acc: 0.9643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f168c902630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLvgEYicBQJk",
        "colab_type": "text"
      },
      "source": [
        "Cabe destacar que los resultados fueron tomados con una baja cantidad de mustras, lo que permitío hacer una gran cantidad de pruebas en poco tiempo.\n",
        "\n",
        "Para usar la version con todas la muestras se puede utilizatr el siguiente directorio:\n",
        "* directory=r\"/content/gdrive/My Drive/2019/Sistemas Inteligentes/Proyecto Air Writing Grupo 4/Entrega 2/DataSet/CrossValidationFolderRedim/Test/\"\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymSbl-uN65rV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63951cd8-c1f1-4f9a-ef87-ae893631075f"
      },
      "source": [
        "model.evaluate_generator(generator=valid_generator,\n",
        "steps=STEP_SIZE_VALID)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33857804962566923, 0.8928571513720921]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ddJLcLmtaJz",
        "colab_type": "text"
      },
      "source": [
        "## Red neuronal normal con 3 capas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXTe64z_vTQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "96e92d9d-370e-484f-e668-1e88b85b237f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras import regularizers, optimizers\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "\n",
        "\n",
        "'''from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np'''\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(3, (3, 3), padding='same',\n",
        "                 input_shape=(1280,64,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(3, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(3, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(3, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(11, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"SGD\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adagrad\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adadelta\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adam\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Adamax\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "# model.compile(optimizer=\"Nadam\"(lr=0.001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=20\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 5s 566ms/step - loss: 7.9853 - acc: 0.0869 - val_loss: 13.5277 - val_acc: 0.1607\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 8.7358 - acc: 0.0664 - val_loss: 14.9668 - val_acc: 0.0714\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 8.9762 - acc: 0.0855 - val_loss: 14.3552 - val_acc: 0.1094\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 7.8281 - acc: 0.0909 - val_loss: 15.2546 - val_acc: 0.0536\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 9.2135 - acc: 0.0830 - val_loss: 14.3912 - val_acc: 0.1071\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 8.9464 - acc: 0.0672 - val_loss: 14.1033 - val_acc: 0.1250\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 8.0552 - acc: 0.0869 - val_loss: 15.5424 - val_acc: 0.0357\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 9.1784 - acc: 0.0751 - val_loss: 14.3912 - val_acc: 0.1071\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 8.3003 - acc: 0.1078 - val_loss: 14.6070 - val_acc: 0.0938\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 8.8831 - acc: 0.0711 - val_loss: 14.6790 - val_acc: 0.0893\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 9.0385 - acc: 0.0859 - val_loss: 14.6790 - val_acc: 0.0893\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 9.4675 - acc: 0.0618 - val_loss: 14.3552 - val_acc: 0.1094\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 8.5927 - acc: 0.0999 - val_loss: 15.2546 - val_acc: 0.0536\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 8.5723 - acc: 0.0934 - val_loss: 14.3912 - val_acc: 0.1071\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 9.2815 - acc: 0.0711 - val_loss: 14.6070 - val_acc: 0.0938\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 8.5133 - acc: 0.0855 - val_loss: 14.6790 - val_acc: 0.0893\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 8.6064 - acc: 0.0736 - val_loss: 14.6790 - val_acc: 0.0893\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 9.0500 - acc: 0.0751 - val_loss: 14.3552 - val_acc: 0.1094\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 7.7092 - acc: 0.0751 - val_loss: 15.5424 - val_acc: 0.0357\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 8.2951 - acc: 0.1211 - val_loss: 14.1033 - val_acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f168bc93438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzWH3vLHbczB",
        "colab_type": "text"
      },
      "source": [
        "### Códigosde ejemplo rescatados de internet\n",
        "from https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GT_w27ObZ8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# initialize our Keras model and compile it\n",
        "model = MiniVGGNet.build(64, 64, 3, len(lb.classes_))\n",
        "opt = SGD(lr=1e-2, momentum=0.9, decay=1e-2 / NUM_EPOCHS)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        " \n",
        "# train the network\n",
        "print(\"[INFO] training w/ generator...\")\n",
        "H = model.fit_generator(\n",
        "\ttrainGen,\n",
        "\tsteps_per_epoch=NUM_TRAIN_IMAGES // BS,\n",
        "\tvalidation_data=testGen,\n",
        "\tvalidation_steps=NUM_TEST_IMAGES // BS,\n",
        "\tepochs=NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXPccgZoqIQ_",
        "colab_type": "text"
      },
      "source": [
        "### Multilayer Perceptron (MLP) for multi-class softmax classification:\n",
        "\n",
        "Ejemplo encontrado que es el cual es el que se intenta seguir como ejemplo para realizar el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWHVSwHTqIRE",
        "colab_type": "code",
        "colab": {},
        "outputId": "4f37a747-16b4-455e-c9dd-eb279c230a78"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Generate dummy data\n",
        "import numpy as np\n",
        "x_train = np.random.random((1000, 20))\n",
        "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
        "x_test = np.random.random((100, 20))\n",
        "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
        "\n",
        "model = Sequential()\n",
        "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
        "# in the first layer, you must specify the expected input data shape:\n",
        "# here, 20-dimensional vectors.\n",
        "model.add(Dense(64, activation='relu', input_dim=20))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128)\n",
        "score = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 0s 472us/step - loss: 2.4573 - acc: 0.0940\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 0s 24us/step - loss: 2.4022 - acc: 0.0950\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 0s 23us/step - loss: 2.3552 - acc: 0.1020\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 0s 23us/step - loss: 2.3251 - acc: 0.1230\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 0s 23us/step - loss: 2.3349 - acc: 0.1040\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 0s 24us/step - loss: 2.3266 - acc: 0.0970\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 0s 23us/step - loss: 2.3160 - acc: 0.1130\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 0s 23us/step - loss: 2.2973 - acc: 0.1250\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 0s 24us/step - loss: 2.3057 - acc: 0.1120\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 0s 23us/step - loss: 2.3105 - acc: 0.1120\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 0s 25us/step - loss: 2.3101 - acc: 0.1110\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 0s 24us/step - loss: 2.3009 - acc: 0.1240\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 0s 27us/step - loss: 2.2996 - acc: 0.1130\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 0s 23us/step - loss: 2.3021 - acc: 0.1280\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 0s 24us/step - loss: 2.2960 - acc: 0.1150\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 0s 25us/step - loss: 2.2999 - acc: 0.1080\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 0s 24us/step - loss: 2.3002 - acc: 0.1150\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 0s 25us/step - loss: 2.2996 - acc: 0.1120\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 0s 25us/step - loss: 2.2942 - acc: 0.1250\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 0s 24us/step - loss: 2.2969 - acc: 0.1150\n",
            "100/100 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}